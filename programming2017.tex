% -*- coding: utf-8; -*-
% vim: set fileencoding=utf-8 :
\documentclass[english]{programming}
%% First parameter: the language is 'english'.
%% Second parameter: use 'submission' for initial submission, remove it for camera-ready (see 4.1)

%\usepackage[backend=biber]{biblatex}
\usepackage{paralist}
\usepackage{url}
\usepackage{import}
\usepackage{tikz}
\usepackage[hyphenbreaks]{breakurl}
\usepackage[pdftex,breaklinks,hyperfootnotes=true]{hyperref}

\def\UrlBreaks{\do\/\do-}

\begin{document}

\title{An Analysis of Introductory Programming Courses at UK Universities}
%\titlerunning{Introductory Programming Courses at UK Universities} %optional, in case that the title is too long; the running title should fit into the top page column

\author{Ellen Murphy}
\authorinfo{is a Commercial Research Associate at the Bath Institute for
  Mathematical Innovation, University of Bath. Contact: \email{e.murphy@bath.ac.uk}}
\affiliation{Institute for Mathematical Innovation, University of
  Bath, UK}
\author{Tom Crick}
\authorinfo{is Professor of Computer Science \& Public Policy at Cardiff
  Metropolitan University. Contact: \email{tcrick@cardiffmet.ac.uk}
  and \url{@ProfTomCrick}}
\affiliation{Department of Computing \& Information Systems, Cardiff
  Metropolitan University, UK}
\author{James H. Davenport}
\authorinfo{is Hebron \& Medlock Professor of Information Technology at
  the University of Bath. Contact: \email{j.h.davenport@bath.ac.uk}
  and \url{@JamesHDavenport}}
\affiliation{Department of Computer Science, University of
  Bath, UK}

\authorrunning{E. Murphy, T. Crick, J. H. Davenport} % Optional, for long author lists

\keywords{introductory programming, programming pedagogy, programming
  environments, programming education, computer science education} % please provide 1--5 keywords


%%%%%%%%%%%%%%%%%%
%% These data MUST be filled for your submission. (see 4.3)
\paperdetails{
  %% perspective options are: art, sciencetheoretical, scienceempirical, engineering.
  %% Choose exactly the one that best describes this work. (see 2.1)
  perspective=scienceempirical,
  %% State one or more areas, separated by a comma. (see 2.2)
  %% Please see list of areas in http://programming-journal.org/cfp/
  %% The list is open-ended, so use other areas if yours is/are not listed.
  area={Programming education},
}
%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%
%% These data are provided by the editors. May be left out on submission.
%\paperdetails{
%  submitted=2016-08-10,
%  published=2016-10-11,
%  year=2017,
%  volume=2,
%  issue=1,
%  articlenumber=1,
%}
%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Please go to https://dl.acm.org/ccs/ccs.cfm and generate your Classification
% System [view CCS TeX Code] stanz and copy _all of it_ to this place.
%% From HERE
 \begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003456.10003457.10003527.10003531</concept_id>
<concept_desc>Social and professional topics~Computing education programs</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003527.10003531.10003533</concept_id>
<concept_desc>Social and professional topics~Computer science education</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003527.10003531.10003533.10011595</concept_id>
<concept_desc>Social and professional topics~CS1</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003527.10003531.10003534</concept_id>
<concept_desc>Social and professional topics~Computer engineering education</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003527.10003531.10003751</concept_id>
<concept_desc>Social and professional topics~Software engineering education</concept_desc>
<concept_significance>500</concept_significance>
</concept>
% <concept>
% <concept_id>10003456.10003457.10003527.10003531.10003537</concept_id>
% <concept_desc>Social and professional topics~Computational science and engineering education</concept_desc>
% <concept_significance>100</concept_significance>
% </concept>
% <concept>
% <concept_id>10011007.10011006.10011008</concept_id>
% <concept_desc>Software and its engineering~General programming languages</concept_desc>
% <concept_significance>500</concept_significance>
% </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Social and professional topics~Computing education programs}
\ccsdesc[500]{Social and professional topics~Computer science education}
\ccsdesc[500]{Social and professional topics~CS1}
\ccsdesc[500]{Social and professional topics~Computer engineering education}
\ccsdesc[500]{Social and professional topics~Software engineering education}
%\ccsdesc[100]{Social and professional topics~Computational science and engineering education}
% \ccsdesc[500]{Software and its engineering~General programming languages}


% To HERE
%%%%%%%%%%%%%%%%%%%%%%%

\maketitle

% Please always include the abstract.
% The abstract MUST be written accorging to the directives stated in 
% http://programming-journal.org/submission/
% Failure to adhere to the abstract directives may result in the paper
% being returned to the authors.
\input{abstract.tex}
%\begin{abstract}
%\end{abstract}


\section{Introduction}\label{intro}

For many years -- and increasingly at all levels of compulsory and
post-compulsory education -- the choice of programming language to
introduce the ``art''~\cite{knuth:2011}, ``science''~\cite{gries:1981}
and ``discipline''~\cite{dijkstra:1976} of computer programming via
key programming principles, constructs, syntax and semantics has been
regularly revisited. Even in the context of what are perceived to be
the most challenging introductory topics in computer science degrees,
numerous key themes across programming frequently
appear~\cite{dale:2006}.

So what makes a good first programming language? Perhaps more
importantly, how are we defining ``good''? The issues surrounding
choosing a first language~\cite{gupta:2004,kaplan:2010} -- and a
search of the ACM Digital Library identified a number of papers of the
form ``{\emph{X as a first programming language}}'', going as far back
as the 1970s~\cite{gries:1974} -- appear to be legion, especially with
wider discussions of precisely what we aim to achieve from teaching
programming~\cite{fincher:1999,schult+bennedsen:2006,brown+altadmri:2017};
from the potential impact on students' grades and
attainment~\cite{simon-et-al:2006,bergin+reilly:2006,porter-et-al:2013,mccartney-et-al:2013,ivanovic-et-al:2015},
to a renewed focus on developing transferable computational thinking
and problem solving
skills~\cite{papert:1993,wing:2008,tedre+denning:2016}. There is a
belief that programming -- as opposed to, say analysis of algorithms,
a closely related theoretical skill -- is fundamentally a craft that
needs immersion and practice~\cite{fincher:1999,milne+rowe:2016}. It
appears that decades of research on the teaching of introductory
programming has had limited effect on classroom
practice~\cite{pears-et-al:2007}; although relevant research exists
across several disciplines including education and cognitive science,
disciplinary differences have often made this material inaccessible to
many computing educators. Furthermore, computer science instructors
have not had access to comprehensive surveys of research in this
area~\cite{mccracken-et-al:2001,pears-et-al:2007}.

However, in Australia and New Zealand there have been longitudinal
data
collections~\cite{deraadt-et-al:2004,mason-et-al:2012,mason+cooper:2014}
surveying the teaching of introductory programming courses in
universities. Surprisingly, such surveys have not been conducted
elsewhere on this scale (in the USA, \cite{guo:2014} only covers the
``top 39'' universities), and this paper reports the findings from
running the first such similar survey in the UK.

We remind the reader that the UK consists of four nations with an
overall population of 64.5 million: England (54.3 million), Scotland
(5.3 million), Wales (3.1 million) and Northern Ireland (1.8
million). In 1997, Scotland and Wales held referendums which
determined in both cases the desire for increased self-government
(along with Northern Ireland and the 1998 Good Friday Agreement),
creating national assemblies to which a variety of powers -- in
particular, education -- were devolved from the UK Parliament. Thus,
we now have an educational policy ecosystem in the UK that was
historically ruled by one parliament but now comprising three devolved
assemblies responsible for four separate education systems.

In the context of increasing international focus on curriculum and
qualification reform to support computer science education and digital
skills in schools, the four education systems of the UK have proposed
and implemented a variety of
changes~\cite{crick+sentance:2011,rs:2012,brown-et-al-sigcse2013,crick+moller-wipsce2015},
particular in England~\cite{brown-et-al-toce2014}, with a new
compulsory computing curriculum for ages 5-16 from September
2014~\cite{dfecomp:2013}. For universities across the UK offering
computer science degrees~\cite{qaacomp:2016}, this school curriculum
reform has had uncertain (and emerging) impact on the delivery of
their undergraduate programmes, with the diversity of the educational
background of applicants likely to increase before it narrows: it is
certainly possible now for prospective students to have anywhere from
zero to four or more years experience (and potentially two school
qualifications) in computer science with some knowledge of
programming.

Since 2012, there has been increasing scrutiny of the quality of
teaching in UK universities, partly linked to the current levels --
and potential future increases -- of tuition fees (generally paid by
the student through government-supported loans), as well as relative
levels of graduate employability and the perceived value of
professional body accreditation by industry. In February 2015, the UK
(but in this respect only responsible for England) Department of
Business, Innovation \& Skills initiated independent reviews of
science, technology, engineering and mathematics (STEM) degree
accreditation and graduate
employability\footnote{\url{https://www.gov.uk/government/collections/graduate-employment-and-accreditation-in-stem-independent-reviews}},
with a specific focus -- the Shadbolt review~\cite{shadbolt:2016} --
on computer science degree accreditation and graduate employability,
reporting back in May 2016. Alongside a number of recommendations to
address the apparently relatively high unemployment rates of computer
sciences graduates, particular on the quality of data, course types,
gender and demographics, the Shadbolt review split generalist
universities in England into three bands (``low'', ``medium'',
``high''), based on the average (across all subjects) entrance tariff
of incoming undergraduates (as defined by the national UCAS
Tariff\footnote{\url{https://www.ucas.com/advisers/guides-and-resources/tariff-2017}});
we have followed the same tariff banding during our analysis of the
English results, so our data should allow comparisons.

\begin{figure}
\begin{center}
\subimport{plots/}{tariffGroupCompareWide.tex}
\caption{The number of responding universities per Nation/Tariff Group\label{fig:TG}}
\end{center}
\end{figure}

Thus, in this evolving environment of new policies and curricula, as
well as the emerging demands of innovative pedagogies and high-quality
learning and teaching for computer science degree programmes, we
present the findings from the first national scale survey of
introductory programming languages at UK universities, providing a
baseline for deeper analysis of the art, science and engineering of
programming. Through this first UK-wide survey of universities, we
identify and analyse trends in student numbers, programming paradigm,
programming languages and environment/tools used, as well as the
underpinning rationale for their selection.

% Other aspects of first programming courses such as instructor
% experience, 
%external delivery of courses: there was none, so irrelevant
%and resources given to students are also examined, 
% along with comparisons to the  Australasian surveys.

%\subsection{Student Numbers}

% \begin{table}[]
% \centering
% \caption{The number of programming languages used in first programming courses.\label{tab:numLangs}}
% \label{tab:numLanguages}
% \begin{tabular}{ccccc}
% \hline
% Languages & 1  & 2  & 3 & 4 \\ \hline
% Courses   & 59 & 17 & 3 & 1 \\ \hline
% \end{tabular}
% \end{table}


\section{Methodology}\label{method}

\subsection{Recruitment of Participants}

To recruit for the survey, a general call for participants was sent
out to the Council of Professors and Heads of Computing (CPHC)
membership; CPHC\footnote{\url{https://cphc.ac.uk}} is the
representative body for university computer science departments in the
UK, with nearly 800 members at over 100 institutions. The survey was
hosted online from mid-May until the end of June 2016, with the
invitation asking for the survey to be passed on to and completed by
the most appropriate person in that institution. Due to the
recruitment method, there were a number of duplicate responses from
certain departments, and these were reconciled by direct enquiry.

\begin{figure}
\begin{center}
\subimport{plots/}{langPercentCompareWide.tex}
\end{center}
\caption{Language popularity by percentage of courses and students
  (excl. The Open University)\label{fig:lang}}
\end{figure}

The questions used in the survey were generously provided by the
authors of the 2013 Australia and New Zealand
survey~\cite{mason+cooper:2014}, so as to allow direct comparison with
the results of this survey. Where possible, questions were left
unchanged, although a small minority were edited to reflect the UK
target audience. As defined in the 2013 Aus/NZ survey, the terminology
``course'' was used for ``{\emph{the basic unit of study that is
completed by students towards a degree, usually studied over a period
of a semester or session, in conjunction with other units of
study}}''.

The first section of the survey asked about the programming
language(s) in use, the reasons for their choice, and their perceived
difficulty and usefulness. Then, questions regarding the use of
environments or development tools; which ones were used, the reasons
for their choice and the perceived difficulty. General questions about
paradigm, instructor experience and external delivery were asked,
along with questions regarding students receiving unauthorised
assistance, and the resources provided to students. Finally,
participants were asked to identify their top three aims when
teaching introductory programming, and were also allowed to provide
further comments.

% @James: I checked the paper - they could rank all reasons, not just top three.  
In the 2013 Aus/NZ survey, participants were asked to rank
the importance of the reasons for choosing a programming language,
environment or tool. Due to technical limitations in the online survey
tool used, it was not possible to do so in this survey, so
Figure~\ref{fig:reasons} only reports counts. Most questions were not
mandatory; the exceptions were ``{\emph{what programming language(s)
are in use?}}'' and a small number of feeder questions to allow the
survey to function correctly.


\section{Results}\label{results}

\subsection{Universities and Courses}
%JHD: we need some discussion of response rates, either here or via
%Figure 1 also showing response rates, as in e-mail to Ellen

Upon completion of the survey, 155 instructors had, at least, started
the survey; 61 of these dropped out before answering the
mandatory questions, and a further 14 were duplicates. Therefore, the
results presented here are drawn from the responses of 80 instructors
from at least 70 institutions. Some participants did not answer all
questions and thus the response rate varies by question.

\begin{figure}
\begin{center}
\subimport{plots/}{reasonsByCourseCompareWide.tex}
\end{center}
\caption{Reasons given for choosing a programming language by percentage for: all languages; Java; and Python\label{fig:reasons}}
\end{figure}

Excluding the Open University's 3200 students, the participants in the
survey represented 13462 students, with a mean of 173 (but a standard
deviation of 88). Looking at Figure~\ref{fig:TG} we see good response
rates, apart from the specialist higher education institutions (most
of whom do not teach computing) and the ``low tariff'' English
ones. Fewer of these teach computing; this factor alone explains the
response rate. In Northern Ireland, we had responses from the two
universities, but not the university colleges, which are historically
initial teacher education colleges.


\subsection{Languages}\label{langs}

%\subsubsection{Choice of Language(s)}

A primary focus of this survey was to identify the programming
languages in use in introductory programming courses. Participants
were asked to select languages from a list of 22 programming languages
and also had the option to choose ``{\emph{Other}}'' and specify a
language not included in the list. The majority of courses surveyed
(59 out of 80, 73.8\%) use only one programming language, with 17
using two (and only three and one institutions using three and four
languages respectively). From the 80 courses, the total number of
{\emph{language instances}} is 106, as some courses use more than one
language to teach introductory programming.

Of the 22 languages provided, 13 were selected at least once. The
relative popularity of languages is shown in Figure~\ref{fig:lang},
where the prevalence is given by the percentage of a language over all
language instances (106 total), and weighted by student numbers (16662
total) per language instance. The programming languages that were not
selected at all were: Actionscript, Ada, Delphi, Eiffel, Fortran,
jBase, Lisp, Ruby and Visual Basic.

\begin{figure}
\begin{center}
\subimport{plots/}{langByTariffPercentWide.tex}
\end{center}%\vskip-12pt  JHD: Oddly, this vskip seems counterproductive
%\caption{The breakdown of programming languages for each of the Tariff Groups.}
%\end{figure}
%
%\begin{figure}
\begin{center}
\subimport{plots/}{TariffByLangPercentWide.tex}
\end{center}
\caption{The breakdown of programming languages by Nation and Tariff Groups\label{fig;LangTariff}}
\end{figure}

The relative popularity of languages is the immediate major difference
with the 2013 Aus/NZ survey; their survey showed a dead heat (27.3\%
of language instances) between Java and Python, with Python winning
(33.7\% to 26.9\%) when weighted by the number of students enrolled on
the course.  Our findings in Figure~\ref{fig:lang} show that Java is a
clear winner by any metric, being used in over half the courses
(61.3\%) and just under half of all language instances (46.2\%), while
the runner-up, Python, is in use in 17.5\% of courses and makes up
13.2\% of language instances. The C family (C, C++ and
C\#)\footnote{One referee queried whether C\# counts as ``C family'',
describing it as ``{\emph{much closer to Java}}''. One can find apparently
authoritative statements in both camps from the language designers of
Java and C\#. Further analysis of the four C\# instances shows four
different patterns: C\# only; a wide range of languages; C++ followed
by C\# and Java followed by C\#.} together is in use in 31.3\% of
introductory programming courses, and scores 23.6\% of language
instances and 19.5\% by students. Figure~\ref{fig:lang} also shows the
effect of student-number weighting \emph{but} we have excluded the
Open University from this weighting, as its 3200 students learning
Python (and Sense, a variant of Scratch) would have distorted the
comparison.

%\subsubsection{Reasons for choice of language}
For each language selected, participants were asked to give the
reasons for choosing that language for the introductory programming
course. Figure~\ref{fig:reasons} shows the frequency of these reasons
for all languages grouped together and for Java and Python
individually. When the reasons given are combined for all languages,
three reasons tie for first place: ``{\emph{relevance to industry}}'';
``{\emph{object-oriented language}}''; and ``{\emph{availability and
cost to students}}'', all chosen by 54.5\% of participants who
answered this question.

Looked at individually, the most popular reason given for choosing
Java is ``{\emph{object-oriented language}}'' at 87.2\%, while Python
scores highest on ``{\emph{pedagogical benefits}}'', at 72.7\%. This
may explain the popularity of Java: Java scores higher on
``{\emph{relevance to industry}}'' and, perhaps somewhat surprisingly,
much higher on ``{\emph{object-oriented language}}'' than Python,
which only scores 18.2\%.

%\subsubsection{Language choice by Nation and Tariff Score}

Figure~\ref{fig;LangTariff} breaks down the choice of language by
nation and tariff group.  It is noticeable that the three English
tariff groups differ significantly, with Python outnumbering Java in
the low tariff universities, and C being almost exclusively in the
high tariff universities. Figure~\ref{fig:utility} gives the
instructors' views on languages. It is noteworthy that Java is among
the most difficult, and not among the pedagogically most useful.

\begin{figure}
\begin{center}
\subimport{plots/}{UseAndDifficultyCompareLanguagesWide.tex}
\end{center}
%\caption{The median of the perceived difficulty and usefulness of language, where 1 is `extremely easy' and 7 is `extremely difficult' for difficulty and 1 is `extremely useful' and 7 is `extremely useless' for usefulness.}%  Answers must have been given by at least two instructors.}
\caption{The median of the perceived difficulty and [pedagogic] usefulness of language, where 1 is `{\emph{extremely easy/useful}}' and 7 is `{\emph{extremely difficult/useless}}'% Answers must have been given by at least two instructors.
\label{fig:utility}}
\end{figure}

For each language chosen, instructors were asked whether the language
was used: for the whole of the first programming course; for the first
part of the first programming course, followed by another; after
another language in the first programming course. Of 93 language
instances, the majority (65\%) are used for the whole of the
introductory programming course, 14.0\% of language instances are used
in the first part of a course and 21.5\% of language instances are
used after another programming language; results are displayed in
Figure~\ref{fig:timing}.

\begin{figure}
\begin{center}
\subimport{plots/}{timingLanguagesWide.tex}
\end{center}
\caption{For each language, whether the language is used: for the whole of the first programming course; for the first part of the first programming course, followed by another; after another language in the first programming course
\label{fig:timing}}
\end{figure}

% \begin{table}[ht]
% \centering
% \caption{The main paradigm in use in the first programming course.}
% \label{tab:paradigm}
% \begin{tabular}{ccccc}
% \hline
% Paradigm & OO & Procedural & Functional & No Answer \\ \hline
% Courses  & 40              & 27         & 7    & 6      \\ \hline
% \end{tabular}
% \end{table}



\begin{figure}
\begin{center}
\subimport{plots/}{paradigmByTariffPercentWide.tex}
\end{center}
\begin{center}
\subimport{plots/}{TariffByParadigmPercentWide.tex}
\end{center}
\caption{The breakdown of the main paradigm in use for every Tariff Group\label{fig:paradigmTariff}}
\end{figure}

\begin{figure}
\begin{center}
\subimport{plots/}{ParadigmByLangPercentWide.tex}
\end{center}
\begin{center}
\subimport{plots/}{LangByParadigmPercentWide.tex}
\end{center}
\caption{The breakdown of the main paradigm in use for each programming language\label{fig:paradigmLang}}
\end{figure}

\subsection{Paradigm Taught}

Instructors were asked which paradigm was being taught in their
introductory programming course, regardless of what is traditionally
thought to apply to the language(s) in use. This question,
understandably, caused some dissatisfaction in the comments section,
with many participants noting that more than one paradigm is taught in
their course. Although this was to be expected, we wanted to be able
to directly compare our results to the 2013 Aus/NZ survey, and so did
not alter the question. The most popular paradigm is object-oriented
with 50\% ($\mathrm{N}=40$, 50\%) followed by procedural
($\mathrm{N}=27$, 33.8\%) and functional ($\mathrm{N}=7$, 8.75\%);
logical was also offered as a choice but was not selected.

%\subsubsection{Paradigm by nation and tariff score}
The results of the previous question were used to analyse -- see
Figure~\ref{fig:paradigmTariff} -- the prevalence of paradigms across
nations and tariff score groups. Caution must be applied when
interpreting these results, as participants could only choose one
paradigm, even though more may be in use.
%{\bf{[@James: Need to add some commentary here.]}}

%\subsubsection{Paradigm by language}

In the same way as above, the languages chosen were analysed -- see
Figure~\ref{fig:paradigmLang} -- with regard to the main paradigm in
use. Again, caution must be applied, as for a given course, only one
paradigm is chosen, even though more than one language and/or paradigm
may be in use. This explains the respondents who used C, but stated
that object-oriented was the main paradigm, for example. More
surprising is the fact that Python was almost exclusively viewed as
procedural.

%{\bf{[@James: Need to add some commentary here.]}}

%\begin{figure}
%\begin{center}
%\subimport{}{TariffByParadigmPercent.tex}
%\end{center}
%\caption{The breakdown of Tariff Groups for each paradigm.}
%\end{figure}
%
%\begin{figure}
%\begin{center}
%\subimport{}{langByParadigmPercent.tex}
%\end{center}\vskip-18pt
%\caption{The breakdown of programming languages in use for each paradigm.}
%\end{figure}

\begin{figure}
\begin{center}
\subimport{plots/}{toolPercentCompareWide.tex}
\caption{Tool or environment popularity by percentage of courses and students\label{fig:tools}}
\end{center}
\end{figure}

\subsection{Instructor Experience}

Participants were asked: ``{\emph{How many years have you been
involved in teaching of introductory programming?}}''. The results,
shown in Table~\ref{tab:yearsTeaching}, indicate that of the survey
participants, the average was between 10-20 years.

%{\bf{[Anything else to be said here?]}}

\begin{table}[ht]
\centering
\caption{The number of years the instructor has been teaching introductory programming.}
\vspace{0.5cm}
\label{tab:yearsTeaching}
\begin{tabular}{ccccccc}
\hline
Years       & \textless 2 & 2 - 5 & 5 - 10 & 10 - 20 & 20 - 30 & \textgreater 30 \\ \hline
Instructors & 3          & 9     & 9      & 27      & 19      & 7              \\ \hline
\end{tabular}
\end{table}

\subsection{IDEs and Tools}

%\subsubsection{Choice of tool/IDE}

Participants in the survey were asked if they encouraged students in
the first programming course to use environments and/or tools beyond
simple text editors and command line compilers. The majority of
participants of this question (74.4\% of 78 instructors) responded
that they did encourage tools. Of the 58 instructors that did select a
tool/IDE, the majority (58.6\%) use only one, with 25.8\% and 10.3\%
using two and three respectively; very few (5.2\%) used four or more,
with one respondent using eight.

% \begin{table}[]
% \centering
% \caption{The number of tools/environments used in first programming courses.\ref{tab:numTools}}
% \label{tab:numTools}
% \begin{tabular}{cccccc}
% \hline
% Tools   & 1  & 2  & 3 & 4 & 8 \\ \hline
% Courses & 34 & 15 & 6 & 2 & 1 \\ \hline
% \end{tabular}
% \end{table} 

\begin{figure}
\begin{center}
\subimport{plots/}{reasonsByCourseCompareToolWide.tex}
\end{center}
\caption{Reasons given for choosing a tool or environment by percentage for: all tools and environments; BlueJ; and Eclipse\label{fig:reasonsTools}}
\end{figure}

The survey asked participants to select the tools and IDEs in use in
their introductory programming course out of a list of 24, with the
option to specify ``{\emph{Other}}''. Of the 24 provided, 12 were
chosen at least once. The relative popularity of IDEs and tools is
shown in Figure~\ref{fig:tools}. The most popular tool/IDE in the
survey was Eclipse, reported in 37.5\% of courses and scoring 25.0\%
of tool/IDE instances, and 26.8\% when weighted by students. Following
this is ``{\emph{No Tool/IDE}}'', which accounts for 27.5\% of
courses. The second most popular tool/IDE is BlueJ, which was reported
in 22.5\% of courses and scored 15.0\% of tool/IDE instances, and
15.5\% when weighted by students. Participants were also asked why
each tool/IDE was chosen for their course, and asked to select from a
list of reasons. The results of this are give in
Figure~\ref{fig:reasonsTools}, for all tools and IDEs grouped
together, and for the two most popular choices, Eclipse and BlueJ. The
tools and IDEs not selected at all were: AdaCore, Alice, App, Browser,
Greenfoot, Jeroo, Jython, KTechLab, MySQL, Pelles, Quincy, Wing101 and
Xcode.

\subsubsection{Reuse of Tool/IDE}

Instructors were also asked whether the tool/IDE was used for an
initial part of the first programming course or throughout the whole
of the course; and whether it was used in any other course in the
degree (Figure~\ref{fig:toolreuse}). 

\begin{figure}
\begin{center}
\subimport{plots/}{timingOtherCourseToolWide.tex}
\end{center}
\caption{For each tool or environment, whether it is used: for an initial part of the first programming course; throughout the whole of the first programming course; in any other course in the degree\label{fig:toolreuse}}
\end{figure}

\subsubsection{Difficulty of Tool/IDE}

In addition to this, instructors were asked to rate how difficult
{\emph{they}} found the tool/IDE on a Likert scale from
``{\emph{Extremely Easy}}'' (1) to ``{\emph{Extremely Difficult}}''
(7), and also how difficult they believed {\emph{the students}} found
the tool/IDE, shown in Figure~\ref{fig:toolhard}.

\begin{figure}
\begin{center}
\subimport{plots/}{DifficultyYouStudentsCompareToolsWide.tex}
\end{center}
\caption{The median difficulty rating of tool for the instructor and students to use, where 1 is `{\emph{extremely easy}}' and 7 is `{\emph{extremely difficult}}'  %Answers must have been given by at least two instructors.
\label{fig:toolhard}}
\end{figure}

We note that, while Eclipse is the most popular tool by some way, it
is also deemed to be most difficult. This, apparently perverse,
practice might be explained by the extent of re-use of Eclipse in
other courses.

\subsection{Other Aspects of the Course}

\subsubsection{External Delivery}

Participants were asked ``{\emph{Do you offer external delivery of
your course? (i.e. do you have options for your course where students
are not required to attend regular lectures, workshops, labs or
tutorials?)}}''. The responses to this question were overwhelmingly in
the negative; 70/74 (94.6\%) answered ``{\emph{No}}''.

\begin{figure}
\begin{center}
\subimport{plots/}{ResourcesWide.tex}
\end{center}\vskip-18pt
\caption{Resources provided to students\label{fig:Resources}}
\end{figure}

\begin{figure}
\begin{center}
\subimport{plots/}{StepsWide.tex}
\end{center}
\caption{Steps taken to determine whether students have received unauthorised assistance on assignments\label{fig:Plagiarise}}
\end{figure}

\subsubsection{Resources Provided to Students}

The questionnaire asked about the resources in terms of examples,
books etc. provided to students. The results are rather similar to the
2013 Aus/NZ survey~\cite[Figure 14]{mason+cooper:2014} and are
displayed in Figure~\ref{fig:Resources}. The most popular resources
selected were: ``{\emph{lecture slides or notes provided by the
lecturer}}'' in first place, ``{\emph{worked examples of programming
problems/solutions}}'' in second, and third place was shared by
``{\emph{textbook is specified}}'' and ``{\emph{discussion
boards/forums}}''.

\subsubsection{Unauthorised Assistance}

The vast majority of instructors surveyed (89.3\%) do consider the
possibility that students or groups of students may be receiving
unauthorised assistance (e.g. from other students in the class, from
people outside the class, or via the internet) when doing
assignments. When asked how concerned they were about this
possibility, 9 answered ``{\emph{not concerned}}'', 39 answered
``{\emph{somewhat concerned}}'' and 17 reported ``{\emph{very
concerned}}''.

We also asked participants: ``{\emph{What steps do you take to try to
determine whether students have received unauthorised assistance on
assignments?}}''. The details are displayed in
Figure~\ref{fig:Plagiarise} and range from ``{\emph{notice unlikely
similarities}}'' (59.1\% of the 66 instructors who responded to this
question) to ``{\emph{interview some students/groups at random}}'',
selected by only five instructors.

% {\bf{[@James: this was one of the questions given to me by Raina, but it's possible that it was only added to the list after [8] was published. So might not be correct to say that it was asked by them.]}} 
%We report our results in Figure~\ref{fig:Plagiarise}, as we think they
%are of general interest.

\begin{figure}
\begin{center}
\subimport{plots/}{AimsWide.tex}
\end{center}
\caption{Aims of the introductory course\label{fig:aims}}
\end{figure}

\subsection{Aims of an Introductory Programming Course}

The 2013 Aus/NZ survey asked their respondents for the aims of their
introductory programming course. They, and we, asked for (up to) three
aims. The authors then attempted to classify the free-text answers
into the same categorisation as \cite{mason+cooper:2014} used. While
it is trivial to map the written aim ``{\emph{Thinking
algorithmically}}'' to ``{\emph{Algorithmic
thinking}}''~\cite{mason+cooper:2014} and so on, many were not so
clear: for example, we mapped ``{\emph{To learn a specific
language}}'' to ``{\emph{Syntax/writing basic code}}''. There were
also a class of aims, such as ``{\emph{Establish professional software
development practices}}'', that seemed coherent, but did not map
clearly to the \cite{mason+cooper:2014} aims; these we have
categorised as ``{\emph{Software Engineering}}''. Results of this
question are shown in Figure~\ref{fig:aims}.


\section{Discussion}\label{discussion}

\subsection{Comparison with Australasian Survey}

Here we compare with the latest Australasian
survey~\cite{mason+cooper:2014}; we have already commented on the
major difference in language choice, which colours many of the other
comparisons. In fact, the UK's language choices seem more similar to
Australasia's 2010 choices~\cite{mason-et-al:2012} and \cite[Table
4]{mason+cooper:2014} than even Australasia's 2013 choices. It is hard
to know which comes first, but we also notice that our
difficulty/utility data (Figure \ref{fig:utility}) is somewhat
different from \cite[Figures 7/8]{mason+cooper:2014}.

Another difference in the tools/environments used is demonstrated by
Figure \ref{fig:tools} versus \cite{mason+cooper:2014}'s Figure
11. There, ``{\emph{None}}'' and ``{\emph{Other}}'' were the top two
categories, with IDLE, at 15\%, the most popular named product. In the
UK, ``{\emph{None}}'' is second, ``{\emph{Other}}'' is sixth and IDLE
eighth. Eclipse, the UK favourite, was an ``also ran'' in
\cite{mason+cooper:2014}.

\subsection{The UK Context}

As presented in Section~\ref{langs}, our findings show that Java is
the most popular introductory programming language in UK universities,
more than twice as popular as Python in second place; the C family of
languages (C, C++ and C\#) together is in use in nearly a third of
introductory programming courses. We were surprised by the viewpoint
expressed of Python, as a multi-paradigm language, as being largely
procedural\footnote{We can only speculate why this is; one reason
could be the nature of many of the texts available:
see~\cite{McMaster2016java}, and for example a popular
freely-available Python text~\cite{Downey2012a} which the third author
has used while teaching teachers introduces classes only in chapters
15-17 (of 19 in total).}; from the authors' experiences, the dominance
of Java has been a trend for the past ten years, but we would expect
to see a steady increase in Python due to influences from the changes
to school curricula in the UK~\cite{brown-et-al-toce2014}.

We note that from a smaller survey conducted in July 2014, Python is
the most popular language for teaching introductory computer science
courses at top-ranked US university departments; specifically, eight
of the top 10 CS departments (80\%), and 27 of the top 39 (69\%),
teach Python in introductory CS0 or CS1 courses~\cite{guo:2014}.  This
together with \cite{mason+cooper:2014} and Figure~\ref{fig:utility}
might make one question the UK's domination by Java, although
longstanding industry popularity as measured by community indices may
still be a significant determining factor~\cite{tiobe:nov2016}.

From a UK education policy perspective, a new national Teaching
Excellence Framework has been proposed, with a core ambition to
``{\emph{to raise the quality and status of teaching in higher
education institutions}}''; excellence is to be measured through a
series of proxy metrics that include student satisfaction, retention
and graduate
employability\footnote{\url{http://www.hefce.ac.uk/lt/tef/}}. There
have been significant sector concerns about the aims of the framework
-- as well as the statistical rigour of the metrics -- more so in the
context of it being used for benchmarking\footnote{Many UK newspapers
produce ``University League Tables'', all based on much the same
published data. The new Teaching Excellence Framework will grade
universities as bronze/silver/gold, and it seems inevitable that the
newspaper league tables will use these in their league tables.} 
``teaching excellence'' (particularly as the TEF will not yet be
conducted at the individual subject level, but at the institutional
level), as well as deciding whether institutions are allowed to raise
tuition fees in the future. It remains to be seen how this will affect
undergraduate computer science degree curricula in UK institutions
going forward, especially if there is renewed demand for meeting the
immediate (but potentially transient) demands of the IT industry with
specific tools, languages and environments, as well as reformed
professional body accreditation as per the 2016 Shadbolt
review~\cite{shadbolt:2016}.

The UK's Higher Education Academy -- the national body which champions
teaching quality -- has previously supported initiatives for improving
learning and teaching in computer science, including innovative
pedagogies for
programming~\cite{crick-et-al-hea:2015,davenport-et-al:latice2016},
but we have not yet seen the necessary development of sustainable
discipline-specific communities of practice, both at the local and
national level, to capture and share best practice\footnote{However, a
new initiative announced by the Royal Society in 2016 appears to be
addressing this in UK schools:
\url{https://royalsociety.org/topics-policy/projects/computing-education/}}.

\section{Future Work}

This initial survey provides valuable context for the analysis of the
art, science and engineering of programming in UK higher education, as
well as how this impacts more broadly across the education pipeline:
through significant curriculum reform, as well as scrutiny of the
effectiveness of pedagogies for teaching principles of programming and
software engineering (in essence: software carpentry, providing the
knowledge, skills and understanding to create useful and usable
software for a variety of domains). Moving forward will require an
mixed economy of rigorous pedagogical research, as well as the
application of personal experiences of languages, tools, environments,
models and styles. Only through this blend of the art, science and
engineering of programming will we see significant steps towards
improving programming (and thus computer science) education in the UK.

\section*{Acknowledgements}

The authors would like to thank the participants for their engagement
with the survey, as well as R. Mason and G. Cooper from Southern Cross
University, Australia, for providing us with their survey and
permission to use it. We are grateful to the GW4 Alliance
(Universities of Bath, Bristol, Cardiff and Exeter) for funding the
survey.

Those data created during this research project that do not infringe
the anonymity of the respondents are openly available from the
University of Bath data archive at
\url{http://doi.org/10.15125/BATH-00246}.

\bibliography{programming2017}

\end{document}

